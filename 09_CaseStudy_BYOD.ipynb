{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a1fae7-64eb-4e70-8099-fbcaeedd5280",
   "metadata": {},
   "source": [
    "# 9. Case Study: Bring Your Own Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4d847-7b7c-4448-b4ab-4bf9b7e89aac",
   "metadata": {},
   "source": [
    "Do you have a dataset that needs to be gap-filled?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24d635-950d-45e0-bf62-a939c712fc8d",
   "metadata": {},
   "source": [
    "In this notebook we repeat the analysis for user supplied data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc689910-9aa8-44a1-bf5f-05d91f16303e",
   "metadata": {},
   "source": [
    "# Download and prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c84ec-1ef4-430b-a53f-0b14ddc367c9",
   "metadata": {},
   "source": [
    "::: {note}\n",
    "The section will be dependent on your own data set. You need to wrangle your data into a single file stored as a `.csv` similar to `dataset.csv`. \n",
    "\n",
    "The first column should be a date or timestamp field.\n",
    "\n",
    "The remaining columns are numerical values for physical measurements. The multivariable imputation methods KNN, MICE, and MissForest are applicable when you have multiple dependent variables taken the the same time. \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7363364-48b2-4d00-b0c3-b4426aa43c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import panel as pn\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1105f3-2276-4dfa-8302-0e229a531650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv', parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477d136-363b-4329-989b-b517a7cebf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6e36e-15d9-4c87-b665-61910d4f3f35",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd84a9-c463-4d9e-9b3a-b1fcd79e4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_sites(df, cmap='Viridis'):\n",
    "    image_data = df.astype('float32').T.values\n",
    "    \n",
    "    x_labels = df.index.strftime('%Y-%m-%d')  # dates → x-axis\n",
    "    y_labels = list(df.columns)               # station-depths → y-axis\n",
    "    \n",
    "    x_coords = np.arange(len(x_labels))\n",
    "    y_coords = np.arange(len(y_labels))\n",
    "    \n",
    "    heatmap = hv.Image((x_coords, y_coords, image_data)).opts(\n",
    "        xaxis='bottom',\n",
    "        xlabel='Date',\n",
    "        ylabel='Station @ Depth',\n",
    "        xticks=list(zip(x_coords[::30], x_labels[::30])),  # every 30th date\n",
    "        yticks=list(zip(y_coords, y_labels)),\n",
    "        xrotation=45,\n",
    "        cmap=cmap,\n",
    "        colorbar=True,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        tools=['hover']\n",
    "    )\n",
    "    return heatmap\n",
    "    \n",
    "plot_all_sites(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5798e-9555-4753-9780-37a5dc114c2b",
   "metadata": {},
   "source": [
    "### Visualize the series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88dc6fcc-9b63-42cb-b7b0-75eb39410af6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a dropdown selector\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m site_selector = \u001b[43mpn\u001b[49m.widgets.Select(name=\u001b[33m'\u001b[39m\u001b[33mSite\u001b[39m\u001b[33m'\u001b[39m, options=\u001b[38;5;28mlist\u001b[39m(df.columns))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhighlight_nan_regions\u001b[39m(label):\n\u001b[32m      6\u001b[39m     series = df[label]\n",
      "\u001b[31mNameError\u001b[39m: name 'pn' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a dropdown selector\n",
    "site_selector = pn.widgets.Select(name='Site', options=list(df.columns))\n",
    "\n",
    "def highlight_nan_regions(label):\n",
    "\n",
    "    series = df[label]\n",
    "    \n",
    "    # Identify NaN regions\n",
    "    is_nan = series.isna()\n",
    "    nan_ranges = []\n",
    "    current_start = None\n",
    "\n",
    "    for date, missing in is_nan.items():\n",
    "        if missing and current_start is None:\n",
    "            current_start = date\n",
    "        elif not missing and current_start is not None:\n",
    "            nan_ranges.append((current_start, date))\n",
    "            current_start = None\n",
    "    if current_start is not None:\n",
    "        nan_ranges.append((current_start, series.index[-1]))\n",
    "\n",
    "    # Create shaded regions\n",
    "    spans = [\n",
    "        hv.VSpan(start, end).opts(color='red', alpha=0.2)\n",
    "        for start, end in nan_ranges\n",
    "    ]\n",
    "\n",
    "    curve = hv.Curve(series, label=label).opts(\n",
    "        width=900, height=250, tools=['hover', 'box_zoom', 'pan', 'wheel_zoom'],\n",
    "        show_grid=True, title=label\n",
    "    )\n",
    "\n",
    "    return curve * hv.Overlay(spans)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ba733-7062-4706-8ef6-5e321ef1e072",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "interactive_plot = hv.DynamicMap(pn.bind(highlight_nan_regions, site_selector))\n",
    "\n",
    "pn.Column(site_selector, interactive_plot, 'Hightlights regions are gaps that need to imputed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8612331-d93a-4e96-8218-e0c20d26594e",
   "metadata": {},
   "source": [
    "## Impute the gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95680bd4-4202-4b05-b70b-1b46d24735f8",
   "metadata": {},
   "source": [
    "We have determined that the `MissForest`appears to work reasonably well when imputing artificially large gaps. \n",
    "\n",
    "We use it to gap fill the missing data in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42445c78-6a85-4c4b-acdb-d4d8570e8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imputeMF import imputeMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b5f1b-1794-4d58-a4ba-bf3f1cefdd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = pd.DataFrame(imputeMF(df.values, 10, print_stats=True), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899712d2-15f5-45f1-8f59-294028002ee6",
   "metadata": {},
   "source": [
    "Save the imputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a973bd-6476-406d-ade2-d787309338b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_imputed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_imputed\u001b[49m.to_csv(\u001b[33m'\u001b[39m\u001b[33mdataset_imputed.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_imputed' is not defined"
     ]
    }
   ],
   "source": [
    "df_imputed.to_csv('dataset_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcb090a-9771-4684-8085-5ae3c2974437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf6449-4782-4c75-b891-dcd55acd2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_imputed_regions(label):\n",
    "\n",
    "    series = df[label]\n",
    "    series_imputed = df_imputed[label]\n",
    "    \n",
    "    # Identify NaN regions\n",
    "    is_nan = series.isna()\n",
    "    nan_ranges = []\n",
    "    current_start = None\n",
    "\n",
    "    for date, missing in is_nan.items():\n",
    "        if missing and current_start is None:\n",
    "            current_start = date\n",
    "        elif not missing and current_start is not None:\n",
    "            nan_ranges.append((current_start, date))\n",
    "            current_start = None\n",
    "    if current_start is not None:\n",
    "        nan_ranges.append((current_start, series.index[-1]))\n",
    "\n",
    "    # Create shaded regions\n",
    "    spans = [\n",
    "        hv.VSpan(start, end).opts(color='red', alpha=0.2)\n",
    "        for start, end in nan_ranges\n",
    "    ]\n",
    "\n",
    "    curve = hv.Curve(series_imputed, label=label).opts(\n",
    "        width=900, height=250, tools=['hover', 'box_zoom', 'pan', 'wheel_zoom'],\n",
    "        show_grid=True, title=label\n",
    "    )\n",
    "\n",
    "    return curve * hv.Overlay(spans)\n",
    "    \n",
    "interactive_plot = hv.DynamicMap(pn.bind(highlight_imputed_regions, site_selector))\n",
    "\n",
    "pn.Column(site_selector, interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60684e4-2eda-4437-8fd3-d25197fc6b8f",
   "metadata": {},
   "source": [
    "Highlighted regions show where the gaps have been imputed.\n",
    "\n",
    "Notice the imputation algorithm gap fills in time intervals where there is very limited information from any other site. Care should be taken in interpretation of interpolated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef859196-e162-4a8a-8e8b-918ebaeb37f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_sites(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d48bb9-6ee5-4295-b200-7d47e6cb4eac",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Apply caution when using these imputed datasets in subsequent analysis steps.  While the imputed regions appears reasonable, they are not true measurements.  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f5119-4846-433f-bc18-4b5f2dbf4a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
